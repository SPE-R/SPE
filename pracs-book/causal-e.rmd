```{r, include=FALSE}
knitr::opts_chunk$set(results='hide', fig.show = 'hide', keep.source=TRUE,include=TRUE,eps=FALSE,prefix.string='./graph/causal')
```
# Causal inference

## Proper adjustment for confounding in regression models

The first exercise of this session will ask you to simulate some data
according to pre-specified causal structure (don't take the particular
example too seriously) and see how you should adjust the analysis to
obtain correct estimates of the causal effects.

Suppose one is interested in the effect of beer-drinking on body weight.
Let's *assume* that in addition to the potential effect of beer on weight, the following is true in reality:

-  Beer-drinking has an effect on the body weight.
-  Men drink more beer than women
-  Men have higher body weight than women
-  People with higher body weight tend to have higher blood pressure
-  Beer-drinking increases blood pressure


The task is to simulate a dataset in accordance with this model, and
subsequently analyse it to see, whether the results would allow us to
conclude the true association structure.


-  Sketch a causal graph (not necessarily with R) to see, how should one generate the data
-  Suppose the actual effect sizes are following:

-  People who drink beer weigh on average $2kg$ more than those who don't.
-  The probability of beer-drinking is 0.2 for females and 0.7 for males
-  Men weigh on average $10kg$ more than women.
-  One kg difference in body weight corresponds in
average to $0.5mmHg$ difference in (systolic) blood pressures.
-  Beer-drinking increases blood pressure by $10mmHg$ in average.
-  Beer-drinking has **no** effect on body weight.


The `R` commands to generate the data are:
```{r beerdata_1, echo=TRUE}
bdat= data.frame(sex = c(rep(0,500),rep(1,500))  )
                   # a data frame with 500 females, 500 males
bdat$beer <- rbinom(1000,1,0.2+0.5*bdat$sex)
bdat$weight <- 60 + 10*bdat$sex + rnorm(1000,0,7)
bdat$bp <- 110 + 0.5*bdat$weight + 10*bdat$beer + rnorm(1000,0,10)
```
-  Now fit the following models for body weight as dependent
  variable and beer-drinking as independent variable. Look, what is
  the estimated effect size:

-  Unadjusted (just simple linear regression)
-  Adjusted for sex
-  Adjusted for sex and blood pressure

```{r beermodels_1, echo=FALSE}
library( Epi )
m1a<-lm(weight~beer, data=bdat)
m2a<-lm(weight~beer+sex, data=bdat)
m3a<-lm(weight~beer+sex+bp, data=bdat)
ci.lin(m1a)
ci.lin(m2a)
ci.lin(m3a)
```

-  What would be the conclusions on the effect of beer on weight, based on the three models? Do they agree? 
Which (if any) of the models gives an unbiased estimate of the
  actual causal effect of interest?

-  How can the answer be seen from the graph?

-  Now change the data-generation algorithm so, that in fact beer-drinking
  does increase the body weight by 2kg. Look, what are
  the conclusions in the above models now. 
Thus the data is generated as before, but the weight variable is computed as:
```{r beerdata_2, echo=TRUE}
bdat$weight <- 60 + 10*bdat$sex + 2*bdat$beer + rnorm(1000,0,7)
```

```{r beermodels_2b, echo=FALSE}
bdat$bp <- 110 +0.5*bdat$weight  + 10*bdat$beer+ rnorm(1000,0,10)  #
m1b<-lm(weight~beer,data=bdat)
m2b<-lm(weight~beer+sex,data=bdat)
m3b<-lm(weight~beer+sex+bp,data=bdat)
ci.lin(m1b)
ci.lin(m2b)    # the correct model
ci.lin(m3b)
```

-  Suppose one is interested in the effect of beer-drinking on blood pressure instead, and is fitting a) an unadjusted model  for blood pressure, with beer as an only covariate; b) a model with beer and sex as covariates. Would either a) or b) give an unbiased estimate for the effect? (You may double-check whether the simulated data is consistent with your answer).

```{r bpmodel, echo=FALSE}
m1bp<-lm(bp~beer,data=bdat)
m2bp<-lm(bp~beer+weight+sex,data=bdat)
ci.lin(m1bp)
ci.lin(m2bp)    # the correct model
```




## DAG tools in the package `dagitty`

There is a software *DAGitty* ([http://www.dagitty.net/](http://www.dagitty.net/)) and also an R package *dagitty* that can be helpful in dealing with DAGs. Let's try to get the answer to the previous exercise using this package. 
```{r dagitty1, echo=TRUE}
if(!("dagitty" %in% installed.packages())) install.packages("dagitty")
library(dagitty)
```


Let's recreate the graph on the lecture slide 23 (but omitting the direct causal effect of interest, $C \rightarrow D$):
```{r dagitty2, echo=TRUE}
g <- dagitty("dag {
    C <- S -> Y -> U -> D 
    C -> Z <- Y 
    Z -> D 
    C <- X -> D 
    C -> Q
    W -> D
  }")
plot(g)
```

To get a more similar look as on the slide, we must supply the coordinates (x increases from left to right, y from top to bottom):

```{r dagitty3, echo=TRUE}
coordinates(g) <- list(x=c(S=1,C=1, Q=1,Y=2,Z=2,X=2,U=3,D=3,W=3), 
                       y=c(U=1, Y=1, S=1, Z=2,  C=3, D=3, X=4, W=4, Q=4) )
plot(g)
```

Let's look at all possible paths from $C$ to $D$:
```{r dagitty4, echo=TRUE}
paths( g, "C", "D" )$paths
```
As you see, one path contains a collider and is therefore a *closed* path and the others are *open*.   

Let's identify the minimal sets of variables needed to adjust the model for $D$ for, to obtain an unbiased estimate of the effect of $C$. You can specify, whether you want to estimate direct or total effect of $C$:

```{r dagitty5, echo=TRUE}
adjustmentSets(g, exposure="C", outcome="D",effect="direct")
adjustmentSets(g, exposure="C", outcome="D",effect="total")
```

Thus, for total effect estimation one should adjust for $X$ and either $Y$ or $S$, whereas for direct effect estimation, one would also need to adjust for $Z$.

You can verify that, these are the variables that will block all open paths from $C$ to $D$. 

**Now try to do the *beer-weight* exercise using *dagitty*: **

-  Create the DAG and plot it
```{r dagitty6, echo=FALSE}
bg <- dagitty("dag {
  SEX -> BEER -> BP 
  SEX -> WEIGHT -> BP
  }")
coordinates(bg) <- list(x=c(BEER=1, SEX=2, BP=2, WEIGHT=3), y=c(SEX=1, BEER=2, WEIGHT=2, BP=3))
plot(bg)
```
-  What are the paths from WEIGHT to BEER?
```{r dagitty7, echo=FALSE}
paths(bg, "BEER", "WEIGHT")
```
-  Will you get the same recommendation for the adjustment variable selection as you found before?
```{r dagitty8, echo=FALSE}
adjustmentSets(bg, exposure="BEER", outcome="WEIGHT")
```


## Instrumental variables estimation: Mendelian randomization
Suppose you want to estimate the effect of Body Mass Index (BMI) on blood glucose level (associated with the risk of diabetes).
 Let's conduct a simulation study to verify that when the exposure-outcome association is confounded, but there is a valid instrument (genotype), one obtains an unbiased estimate of the causal effect. 

-  Start by generating the genotype variable as *Binomial(2,p)*, with $p=0.2$ (and look at the resulting genotype frequencies):
```{r mrdat1, echo=TRUE}
 n <- 10000
 mrdat <- data.frame(G = rbinom(n,2,0.2))
 table(mrdat$G)
```
-  Also generate the confounder variable U 
```{r mrdat2, echo=TRUE}
mrdat$U <- rnorm(n)
```

-  Generate a continuous (normally distributed) exposure variable $BMI$ so that it depends on $G$ and $U$. 
Check with linear regression, whether there is enough power to get significant parameter estimates.  
For instance:
```{r mrdat3, echo=T}
mrdat$BMI <- with(mrdat, 25 + 0.7*G + 2*U + rnorm(n) )
```
-  Finally generate $Y$ ("Blood glucose level") so that it depends on $BMI$ and $U$ (but not on $G$).
```{r mrdat4, echo=TRUE}
mrdat$Y <- with(mrdat, 3 + 0.1*BMI - 1.5*U + rnorm(n,0,0.5) )
```
-  Verify, that simple regression model for $Y$, with $BMI$ as a covariate, results in a biased 
estimate of the causal effect (parameter estimate is different from what was generated) 
```{r mrmod1, echo=F}
mxy<-lm(Y ~ BMI, data=mrdat)
ci.lin(mxy)
```
How different is the estimate from 0.1?  

-   Estimate a regression model for $Y$ with two covariates, $G$ and $BMI$. Do you see a significant effect of $G$?
Could you explain analytically, why one may see a significant parameter estimate for $G$ there?
```{r mrmod2, echo=F}
mxyg<-lm(Y ~ G + BMI, data=mrdat)
ci.lin(mxyg)
```

-  Find an IV (instrumental variables) estimate, using G as an instrument, by following the algorithm 
in the lecture notes (use two linear models and find a ratio of the parameter estimates). 
Does the estimate get closer to the generated effect size?
```{r mrmod3, echo=T}
mgx<-lm(BMI ~ G, data=mrdat)
ci.lin(mgx)  # check the instrument effect
bgx<-mgx$coef[2]   # save the 2nd coefficient (coef of G) 
mgy<-lm(Y ~ G, data=mrdat)
ci.lin(mgy)
bgy<-mgy$coef[2]
causeff <- bgy/bgx
causeff    # closer to 0.1?
```

-   A proper simulation study would require the analysis to be run several times, to see the extent of variability in the parameter estimates. 
A simple way to do it here would be using a `for`-loop. Modify the code as follows (exactly the same commands as executed so far, adding a few lines of code to the beginning and to the end):
```{r mrsim, echo=TRUE}
n <- 10000
# initializing simulations:
# 30 simulations (change it, if you want more):
nsim<-30       
mr<-rep(NA,nsim)   # empty vector for the outcome parameters
for (i in 1:nsim) { # start the loop
## Exactly the same commands as before:
mrdat <- data.frame(G = rbinom(n,2,0.2))
mrdat$U <- rnorm(n)
mrdat$BMI <- with(mrdat, 25 + 0.7*G + 2*U + rnorm(n) )
mrdat$Y <- with(mrdat, 3 + 0.1*BMI - 1.5*U + rnorm(n,0,0.5) )
mgx<-lm(BMI ~ G, data=mrdat)
bgx<-mgx$coef[2]
mgy<-lm(Y ~ G, data=mrdat)
bgy<-mgy$coef[2]
# Save the i'th parameter estimate:
mr[i]<-bgy/bgx
}   # end the loop
```
Now look at the distribution of the parameter estimate:
```{r mrsim2, echo=T}
summary(mr)    
```

-  (*optional*) Change the code of simulations so that the assumptions are violated: add a weak direct effect of the genotype G to the equation that generates $Y$:
```{r mrsim3, echo=TRUE}
mrdat$Y <- with(mrdat, 3 + 0.1*BMI - 1.5*U + 0.05*G + rnorm(n,0,0.5) )
```
Repeat the simulation study to see, what is the bias in the average estimated causal effect of $BMI$ on $Y$.

-  (*optional*) Using library `sem`  and function `tsls`, one can obtain a two-stage least squares estimate for the  
causal effect and also the proper standard error. Do you get the same estimate as before? 
```{r tsls, echo=TRUE}
if(!("sem" %in% installed.packages())) install.packages("sem")
library(sem)
summary(tsls(Y ~ BMI, ~G, data=mrdat))
```
(There are also several other R packages for IV estimation and Mendelian Randomization (*MendelianRandomization* for instance))




## Why are simulation exercises useful for causal inference?

If we simulate the data, we know the data-generating mechanism and the *true* causal effects. So this is a way to check, whether 
an analysis approach will lead to estimates that correspond to what is generated. One could expect to see similar phenomena in real
data analysis, if the data-generation mechanism is similar to what was used in simulations.


